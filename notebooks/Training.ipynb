{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week-4: Swin Transformer 3D Training (OPTIMIZED FOR 7,235 PATCHES)\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Project:** BraTS2020 Brain Tumor Segmentation using Swin Transformer 3D\n",
    "\n",
    "**Dataset:** 7,235 patches (5,789 train / 1,446 val)\n",
    "\n",
    "**Key Improvements:**\n",
    "- ‚úÖ Focal Loss for handling class imbalance\n",
    "- ‚úÖ EXTREME class weights (25√ó for rare tumor classes)\n",
    "- ‚úÖ Adjusted for 93% tumor patch ratio\n",
    "- ‚úÖ Higher learning rate (5e-4) for faster convergence\n",
    "- ‚úÖ 100 epochs training with warmup\n",
    "- ‚úÖ Tumor-focused metrics tracking\n",
    "- ‚úÖ Per-step scheduler updates\n",
    "\n",
    "**Expected Results (with 7,235 patches):**\n",
    "- Necrotic Dice: 0.60-0.75 (was 0.02)\n",
    "- Edema Dice: 0.85-0.92 (was 0.65)\n",
    "- Enhancing Dice: 0.65-0.80 (was 0.02)\n",
    "- Tumor Mean Dice: 0.70-0.82 (was 0.23)\n",
    "\n",
    "**Training Time:** ~8-10 hours on RTX 4060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Set random seeds\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WEEK-4: SWIN TRANSFORMER 3D TRAINING (OPTIMIZED FOR 7,235 PATCHES)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Running on CPU - Training will be slow\")\n",
    "print(f\"Number of CPU cores: {os.cpu_count()}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration (OPTIMIZED - 40 EPOCHS)\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration for training pipeline.\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = os.path.join('..', 'processed_data')\n",
    "    CHECKPOINT_DIR = os.path.join('..', 'checkpoints')\n",
    "    RESULTS_DIR = os.path.join('..', 'results')\n",
    "    PLOTS_DIR = os.path.join('..', 'plots')\n",
    "    \n",
    "    # Model architecture\n",
    "    IN_CHANNELS = 4\n",
    "    NUM_CLASSES = 4\n",
    "    EMBED_DIM = 48\n",
    "    DEPTHS = [2, 2, 2, 2]\n",
    "    NUM_HEADS = [3, 6, 12, 24]\n",
    "    WINDOW_SIZE = (4, 4, 4)\n",
    "    PATCH_SIZE = 4\n",
    "    \n",
    "    # Data\n",
    "    IMAGE_SIZE = (64, 64, 64)\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_WORKERS = 0\n",
    "    \n",
    "    # Training - OPTIMIZED FOR EFFICIENCY\n",
    "    EPOCHS = 40  # Sweet spot: good performance without wasting time\n",
    "    LEARNING_RATE = 3e-4  # Reduced for stability\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    WARMUP_EPOCHS = 5  # Reduced proportionally\n",
    "    \n",
    "    # Loss weights\n",
    "    DICE_WEIGHT = 0.7\n",
    "    FOCAL_WEIGHT = 0.3\n",
    "    \n",
    "    # Class weights - REBALANCED (prevents collapse)\n",
    "    CLASS_WEIGHTS = [1.0, 15.0, 8.0, 15.0]  # Background, Necrotic, Edema, Enhancing\n",
    "    \n",
    "    # Data augmentation\n",
    "    USE_AUGMENTATION = True\n",
    "    FLIP_PROB = 0.5\n",
    "    ROTATE_PROB = 0.5\n",
    "    INTENSITY_SHIFT_PROB = 0.5\n",
    "    \n",
    "    # Mixed precision training\n",
    "    USE_AMP = True\n",
    "    \n",
    "    # Checkpointing\n",
    "    SAVE_EVERY_N_EPOCHS = 10\n",
    "    SAVE_BEST_ONLY = True\n",
    "    \n",
    "    # Early stopping - TIGHTER\n",
    "    PATIENCE = 12  # Stop if no improvement for 12 epochs (was 20)\n",
    "    MIN_DELTA = 0.001\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "for directory in [config.CHECKPOINT_DIR, config.RESULTS_DIR, config.PLOTS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION (OPTIMIZED - 40 EPOCHS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Epochs: {config.EPOCHS} (efficient sweet spot)\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {config.LEARNING_RATE} (stable)\")\n",
    "print(f\"Warmup epochs: {config.WARMUP_EPOCHS}\")\n",
    "print(f\"Loss weights: {config.DICE_WEIGHT} √ó Dice + {config.FOCAL_WEIGHT} √ó Focal\")\n",
    "print(f\"\\nüéØ CLASS WEIGHTS (REBALANCED - prevents collapse):\")\n",
    "print(f\"  {config.CLASS_WEIGHTS}\")\n",
    "print(f\"  [Background, Necrotic, Edema, Enhancing]\")\n",
    "print(f\"  Background: 1.0√ó (stable baseline)\")\n",
    "print(f\"  Necrotic: 15√ó (high but not extreme)\")\n",
    "print(f\"  Edema: 8√ó (moderate emphasis)\")\n",
    "print(f\"  Enhancing: 15√ó (high but not extreme)\")\n",
    "print(f\"\\n‚è±Ô∏è  Expected training time:\")\n",
    "print(f\"  ~23-24 hours (vs 58 hours for 100 epochs)\")\n",
    "print(f\"  ~35 minutes per epoch\")\n",
    "print(f\"\\nüìä Expected final performance:\")\n",
    "print(f\"  Tumor Mean Dice: 0.60-0.70 (excellent!)\")\n",
    "print(f\"  Necrotic: 0.50-0.65\")\n",
    "print(f\"  Edema: 0.65-0.80\")\n",
    "print(f\"  Enhancing: 0.60-0.75\")\n",
    "print(f\"\\nEarly stopping:\")\n",
    "print(f\"  Patience: {config.PATIENCE} epochs\")\n",
    "print(f\"  Will stop automatically if plateau detected\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Augmentation (FIXED DIMENSIONS)\n",
    "\n",
    "class Augmentation3D:\n",
    "    \"\"\"3D data augmentation for medical images.\"\"\"\n",
    "    \n",
    "    def __init__(self, flip_prob=0.5, rotate_prob=0.5, intensity_prob=0.5):\n",
    "        self.flip_prob = flip_prob\n",
    "        self.rotate_prob = rotate_prob\n",
    "        self.intensity_prob = intensity_prob\n",
    "    \n",
    "    def random_flip(self, image, mask):\n",
    "        \"\"\"\n",
    "        Random flipping along each spatial axis.\n",
    "        \n",
    "        Args:\n",
    "            image: (C, D, H, W) = (4, 64, 64, 64)\n",
    "            mask: (D, H, W) = (64, 64, 64)\n",
    "        \"\"\"\n",
    "        if np.random.random() < self.flip_prob:\n",
    "            axis_choice = np.random.choice([0, 1, 2])\n",
    "            image = torch.flip(image, dims=[axis_choice + 1])\n",
    "            mask = torch.flip(mask, dims=[axis_choice])\n",
    "        return image, mask\n",
    "    \n",
    "    def random_rotate_90(self, image, mask):\n",
    "        \"\"\"\n",
    "        Random 90-degree rotation in axial plane (H-W plane).\n",
    "        \n",
    "        Args:\n",
    "            image: (C, D, H, W) = (4, 64, 64, 64)\n",
    "            mask: (D, H, W) = (64, 64, 64)\n",
    "        \"\"\"\n",
    "        if np.random.random() < self.rotate_prob:\n",
    "            k = np.random.randint(1, 4)\n",
    "            image = torch.rot90(image, k, dims=[2, 3])\n",
    "            mask = torch.rot90(mask, k, dims=[1, 2])\n",
    "        return image, mask\n",
    "    \n",
    "    def random_intensity_shift(self, image, mask):\n",
    "        \"\"\"\n",
    "        Random intensity shift for MRI modalities.\n",
    "        \n",
    "        Args:\n",
    "            image: (C, D, H, W) = (4, 64, 64, 64)\n",
    "            mask: (D, H, W) = (64, 64, 64)\n",
    "        \"\"\"\n",
    "        if np.random.random() < self.intensity_prob:\n",
    "            shift = torch.randn(image.shape[0], 1, 1, 1) * 0.1\n",
    "            image = image + shift\n",
    "        return image, mask\n",
    "    \n",
    "    def __call__(self, image, mask):\n",
    "        \"\"\"Apply augmentation pipeline.\"\"\"\n",
    "        image, mask = self.random_flip(image, mask)\n",
    "        image, mask = self.random_rotate_90(image, mask)\n",
    "        image, mask = self.random_intensity_shift(image, mask)\n",
    "        return image, mask\n",
    "\n",
    "print(\"‚úì Data augmentation class defined (FIXED DIMENSIONS)\")\n",
    "print(\"  ‚Ä¢ Random flip - along D, H, or W axis\")\n",
    "print(\"  ‚Ä¢ Random 90¬∞ rotation - in axial (H-W) plane\")\n",
    "print(\"  ‚Ä¢ Random intensity shift - per modality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Class\n",
    "\n",
    "class BraTSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    BraTS Dataset for loading preprocessed 3D patches.\n",
    "    \n",
    "    Returns:\n",
    "        image: (4, D, H, W) - 4 MRI modalities\n",
    "        mask: (D, H, W) - segmentation labels {0, 1, 2, 3}\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, split='train', augmentation=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "        # Paths\n",
    "        self.image_dir = os.path.join(data_dir, split, 'images')\n",
    "        self.mask_dir = os.path.join(data_dir, split, 'masks')\n",
    "        \n",
    "        # Get file lists\n",
    "        self.image_files = sorted([f for f in os.listdir(self.image_dir) if f.endswith('.npy')])\n",
    "        self.mask_files = sorted([f for f in os.listdir(self.mask_dir) if f.endswith('.npy')])\n",
    "        \n",
    "        assert len(self.image_files) == len(self.mask_files), \\\n",
    "            f\"Mismatch: {len(self.image_files)} images vs {len(self.mask_files)} masks\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load data\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "        \n",
    "        image = np.load(image_path)\n",
    "        mask = np.load(mask_path)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        \n",
    "        # Remap BraTS labels to consecutive classes\n",
    "        mask = mask.clone()\n",
    "        mask[mask == 4] = 3\n",
    "        \n",
    "        # Apply augmentation (only for training)\n",
    "        if self.augmentation and self.split == 'train':\n",
    "            image, mask = self.augmentation(image, mask)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Initialize augmentation\n",
    "augmentation = Augmentation3D(\n",
    "    flip_prob=config.FLIP_PROB,\n",
    "    rotate_prob=config.ROTATE_PROB,\n",
    "    intensity_prob=config.INTENSITY_SHIFT_PROB\n",
    ") if config.USE_AUGMENTATION else None\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_dataset = BraTSDataset(config.DATA_DIR, split='train', augmentation=augmentation)\n",
    "val_dataset = BraTSDataset(config.DATA_DIR, split='val', augmentation=None)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Total samples: {len(train_dataset) + len(val_dataset)}\")\n",
    "\n",
    "# Verify expected counts\n",
    "if len(train_dataset) != 5789 or len(val_dataset) != 1446:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Sample counts don't match expected!\")\n",
    "    print(f\"   Expected: 5,789 train / 1,446 val\")\n",
    "    print(f\"   Got: {len(train_dataset)} train / {len(val_dataset)} val\")\n",
    "    print(f\"   This may indicate data loading issues.\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Dataset sizes match expected: 5,789 train / 1,446 val\")\n",
    "\n",
    "# Test loading\n",
    "sample_img, sample_mask = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "print(f\"  Image: {sample_img.shape}\")\n",
    "print(f\"  Mask: {sample_mask.shape}\")\n",
    "print(f\"  Mask labels: {torch.unique(sample_mask).tolist()}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: DataLoaders\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"‚úì DataLoaders created\")\n",
    "print(f\"  Train batches per epoch: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"\\nüí° Training info:\")\n",
    "print(f\"  Steps per epoch: {len(train_loader)}\")\n",
    "print(f\"  Estimated time per epoch: ~30-40 minutes\")\n",
    "print(f\"  Total training time: ~8-10 hours (100 epochs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Swin Transformer 3D Building Blocks\n",
    "\n",
    "class PatchEmbed3D(nn.Module):\n",
    "    \"\"\"3D Patch Embedding layer.\"\"\"\n",
    "    def __init__(self, patch_size=4, in_chans=4, embed_dim=96):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        B, C, D, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        x = x.transpose(1, 2).view(B, C, D, H, W)\n",
    "        return x\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"Partition input into windows with padding if necessary.\"\"\"\n",
    "    B, D, H, W, C = x.shape\n",
    "    Wd, Wh, Ww = window_size\n",
    "    \n",
    "    pad_d = (Wd - D % Wd) % Wd\n",
    "    pad_h = (Wh - H % Wh) % Wh\n",
    "    pad_w = (Ww - W % Ww) % Ww\n",
    "    \n",
    "    if pad_d > 0 or pad_h > 0 or pad_w > 0:\n",
    "        x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h, 0, pad_d))\n",
    "    \n",
    "    B, D, H, W, C = x.shape\n",
    "    x = x.view(B, D // Wd, Wd, H // Wh, Wh, W // Ww, Ww, C)\n",
    "    windows = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous()\n",
    "    windows = windows.view(-1, Wd * Wh * Ww, C)\n",
    "    \n",
    "    return windows, (D, H, W)\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, original_size):\n",
    "    \"\"\"Reverse window partition.\"\"\"\n",
    "    Wd, Wh, Ww = window_size\n",
    "    D, H, W = original_size\n",
    "    C = windows.shape[-1]\n",
    "    \n",
    "    B = int(windows.shape[0] / (D * H * W / Wd / Wh / Ww))\n",
    "    x = windows.view(B, D // Wd, H // Wh, W // Ww, Wd, Wh, Ww, C)\n",
    "    x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous()\n",
    "    x = x.view(B, D, H, W, C)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class WindowAttention3D(nn.Module):\n",
    "    \"\"\"Window-based multi-head self-attention.\"\"\"\n",
    "    def __init__(self, dim, window_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformerBlock3D(nn.Module):\n",
    "    \"\"\"Swin Transformer Block.\"\"\"\n",
    "    def __init__(self, dim, num_heads, window_size, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = WindowAttention3D(dim, window_size, num_heads)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_hidden_dim, dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, D, H, W, C = x.shape\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        x_windows, padded_size = window_partition(x, self.window_size)\n",
    "        attn_windows = self.attn(x_windows)\n",
    "        x = window_reverse(attn_windows, self.window_size, padded_size)\n",
    "        x = x[:, :D, :H, :W, :].contiguous()\n",
    "        \n",
    "        x = shortcut + x\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformer3D(nn.Module):\n",
    "    \"\"\"Swin Transformer 3D for segmentation.\"\"\"\n",
    "    def __init__(self, in_chans=4, num_classes=4, embed_dim=48, \n",
    "                 depths=[2,2,2,2], num_heads=[3,6,12,24], \n",
    "                 window_size=(4,4,4), patch_size=4):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.patch_embed = PatchEmbed3D(patch_size, in_chans, embed_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = nn.ModuleList([\n",
    "                SwinTransformerBlock3D(\n",
    "                    dim=int(embed_dim * 2 ** i_layer),\n",
    "                    num_heads=num_heads[i_layer],\n",
    "                    window_size=window_size\n",
    "                ) for _ in range(depths[i_layer])\n",
    "            ])\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.downsample_layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers - 1):\n",
    "            downsample_layer = nn.Conv3d(\n",
    "                int(embed_dim * 2 ** i_layer),\n",
    "                int(embed_dim * 2 ** (i_layer + 1)),\n",
    "                kernel_size=2, stride=2\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "        \n",
    "        self.upsample_layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers - 1, 0, -1):\n",
    "            upsample_layer = nn.Sequential(\n",
    "                nn.ConvTranspose3d(\n",
    "                    int(embed_dim * 2 ** i_layer),\n",
    "                    int(embed_dim * 2 ** (i_layer - 1)),\n",
    "                    kernel_size=2, stride=2\n",
    "                ),\n",
    "                nn.BatchNorm3d(int(embed_dim * 2 ** (i_layer - 1))),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            self.upsample_layers.append(upsample_layer)\n",
    "        \n",
    "        self.final_upsample = nn.Sequential(\n",
    "            nn.ConvTranspose3d(embed_dim, embed_dim, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.BatchNorm3d(embed_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.segmentation_head = nn.Conv3d(embed_dim, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, D, H, W = x.shape\n",
    "        original_size = (D, H, W)\n",
    "        \n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        for i, layer_blocks in enumerate(self.layers):\n",
    "            B, C, D, H, W = x.shape\n",
    "            x = x.permute(0, 2, 3, 4, 1).contiguous()\n",
    "            \n",
    "            for block in layer_blocks:\n",
    "                x = block(x)\n",
    "            \n",
    "            x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "            \n",
    "            if i < self.num_layers - 1:\n",
    "                x = self.downsample_layers[i](x)\n",
    "        \n",
    "        for upsample_layer in self.upsample_layers:\n",
    "            x = upsample_layer(x)\n",
    "        \n",
    "        x = self.final_upsample(x)\n",
    "        \n",
    "        _, _, D_out, H_out, W_out = x.shape\n",
    "        if (D_out, H_out, W_out) != original_size:\n",
    "            x = F.interpolate(x, size=original_size, mode='trilinear', align_corners=False)\n",
    "        \n",
    "        x = self.segmentation_head(x)\n",
    "        return x\n",
    "\n",
    "print(\"‚úì Swin Transformer 3D architecture loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Loss Functions (WITH EXTREME CLASS WEIGHTS)\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for multi-class segmentation with class weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, smooth=1e-6, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def forward(self, predictions, targets, num_classes=4):\n",
    "        predictions = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        targets_one_hot = F.one_hot(targets, num_classes=num_classes)\n",
    "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        dice_scores = []\n",
    "        for c in range(num_classes):\n",
    "            pred_c = predictions[:, c]\n",
    "            target_c = targets_one_hot[:, c]\n",
    "            \n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            union = pred_c.sum() + target_c.sum()\n",
    "            \n",
    "            dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "            \n",
    "            if self.class_weights is not None:\n",
    "                dice = dice * self.class_weights[c]\n",
    "            \n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            total_weight = sum(self.class_weights)\n",
    "            dice_score = torch.stack(dice_scores).sum() / total_weight\n",
    "        else:\n",
    "            dice_score = torch.stack(dice_scores).mean()\n",
    "        \n",
    "        return 1 - dice_score\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for handling class imbalance.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        probs = F.softmax(predictions, dim=1)\n",
    "        \n",
    "        targets_one_hot = F.one_hot(targets, num_classes=predictions.shape[1])\n",
    "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        pt = (probs * targets_one_hot).sum(dim=1)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "        ce_loss = F.cross_entropy(predictions, targets, reduction='none')\n",
    "        focal_loss = focal_weight * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = torch.zeros_like(focal_loss)\n",
    "            for c in range(len(self.alpha)):\n",
    "                alpha_t[targets == c] = self.alpha[c]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined Dice + Focal Loss with EXTREME class weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, dice_weight=0.7, focal_weight=0.3, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "        \n",
    "        if class_weights is not None:\n",
    "            class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "        else:\n",
    "            class_weights_tensor = None\n",
    "        \n",
    "        self.dice_loss = DiceLoss(class_weights=class_weights)\n",
    "        self.focal_loss = FocalLoss(alpha=class_weights, gamma=2.0)\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        dice = self.dice_loss(predictions, targets)\n",
    "        focal = self.focal_loss(predictions, targets)\n",
    "        combined = self.dice_weight * dice + self.focal_weight * focal\n",
    "        return combined, dice, focal\n",
    "\n",
    "\n",
    "def calculate_dice_score(predictions, targets, num_classes=4):\n",
    "    \"\"\"Calculate Dice score per class.\"\"\"\n",
    "    predictions = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    dice_scores = []\n",
    "    for c in range(num_classes):\n",
    "        pred_c = (predictions == c).float()\n",
    "        target_c = (targets == c).float()\n",
    "        \n",
    "        intersection = (pred_c * target_c).sum()\n",
    "        union = pred_c.sum() + target_c.sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            dice_scores.append(1.0)\n",
    "        else:\n",
    "            dice = (2. * intersection) / (union + 1e-6)\n",
    "            dice_scores.append(dice.item())\n",
    "    \n",
    "    return dice_scores\n",
    "\n",
    "print(\"‚úì Loss functions defined with EXTREME CLASS WEIGHTS\")\n",
    "print(\"  ‚Ä¢ DiceLoss with class weights [0.3, 25, 12, 25]\")\n",
    "print(\"  ‚Ä¢ FocalLoss (gamma=2.0) for hard examples\")\n",
    "print(\"  ‚Ä¢ CombinedLoss (Dice + Focal)\")\n",
    "print(f\"  ‚Ä¢ Class weights optimized for 93% tumor ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Initialize Model and Training Components\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INITIALIZING TRAINING COMPONENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Model\n",
    "model = SwinTransformer3D(\n",
    "    in_chans=config.IN_CHANNELS,\n",
    "    num_classes=config.NUM_CLASSES,\n",
    "    embed_dim=config.EMBED_DIM,\n",
    "    depths=config.DEPTHS,\n",
    "    num_heads=config.NUM_HEADS,\n",
    "    window_size=config.WINDOW_SIZE,\n",
    "    patch_size=config.PATCH_SIZE\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úì Model initialized\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: ~{total_params * 4 / 1024**2:.2f} MB\")\n",
    "\n",
    "# Loss with EXTREME class weights\n",
    "criterion = CombinedLoss(\n",
    "    dice_weight=config.DICE_WEIGHT,\n",
    "    focal_weight=config.FOCAL_WEIGHT,\n",
    "    class_weights=config.CLASS_WEIGHTS\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\n‚úì Loss function initialized\")\n",
    "print(f\"  Type: Combined Dice + Focal Loss\")\n",
    "print(f\"  Weights: {config.DICE_WEIGHT} √ó Dice + {config.FOCAL_WEIGHT} √ó Focal\")\n",
    "print(f\"  Class weights (EXTREME): {config.CLASS_WEIGHTS}\")\n",
    "print(f\"  [Background: 0.3√ó, Necrotic: 25√ó, Edema: 12√ó, Enhancing: 25√ó]\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Optimizer: AdamW\")\n",
    "print(f\"  Learning rate: {config.LEARNING_RATE}\")\n",
    "print(f\"  Weight decay: {config.WEIGHT_DECAY}\")\n",
    "\n",
    "# Scheduler with warmup\n",
    "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "num_training_steps = config.EPOCHS * len(train_loader)\n",
    "num_warmup_steps = config.WARMUP_EPOCHS * len(train_loader)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Scheduler: CosineAnnealingLR with warmup\")\n",
    "print(f\"  Warmup epochs: {config.WARMUP_EPOCHS}\")\n",
    "print(f\"  Total steps: {num_training_steps:,}\")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler() if config.USE_AMP else None\n",
    "if config.USE_AMP:\n",
    "    print(f\"\\n‚úì Mixed precision (AMP) enabled\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Training and Validation Functions\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, scheduler, device, scaler, epoch):\n",
    "    \"\"\"Train for one epoch with per-step scheduler update.\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_dice_loss = 0\n",
    "    total_focal_loss = 0\n",
    "    dice_scores_per_class = [[] for _ in range(config.NUM_CLASSES)]\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}/{config.EPOCHS} [TRAIN]\")\n",
    "    \n",
    "    for batch_idx, (images, masks) in enumerate(progress_bar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if config.USE_AMP:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss, dice_loss, focal_loss = criterion(outputs, masks)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss, dice_loss, focal_loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Update scheduler per step\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate Dice scores\n",
    "        dice_per_class = calculate_dice_score(outputs, masks)\n",
    "        for c in range(config.NUM_CLASSES):\n",
    "            dice_scores_per_class[c].append(dice_per_class[c])\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_dice_loss += dice_loss.item()\n",
    "        total_focal_loss += focal_loss.item()\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'dice': f'{dice_loss.item():.4f}',\n",
    "            'tumor_dice': f'{np.mean(dice_per_class[1:]):.3f}',\n",
    "            'lr': f'{current_lr:.6f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice_loss = total_dice_loss / len(dataloader)\n",
    "    avg_focal_loss = total_focal_loss / len(dataloader)\n",
    "    avg_dice_per_class = [np.mean(scores) for scores in dice_scores_per_class]\n",
    "    \n",
    "    return avg_loss, avg_dice_loss, avg_focal_loss, avg_dice_per_class\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_dice_loss = 0\n",
    "    total_focal_loss = 0\n",
    "    dice_scores_per_class = [[] for _ in range(config.NUM_CLASSES)]\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch}/{config.EPOCHS} [VAL]  \")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(progress_bar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            if config.USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss, dice_loss, focal_loss = criterion(outputs, masks)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss, dice_loss, focal_loss = criterion(outputs, masks)\n",
    "            \n",
    "            dice_per_class = calculate_dice_score(outputs, masks)\n",
    "            for c in range(config.NUM_CLASSES):\n",
    "                dice_scores_per_class[c].append(dice_per_class[c])\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_dice_loss += dice_loss.item()\n",
    "            total_focal_loss += focal_loss.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{dice_loss.item():.4f}',\n",
    "                'tumor_dice': f'{np.mean(dice_per_class[1:]):.3f}'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice_loss = total_dice_loss / len(dataloader)\n",
    "    avg_focal_loss = total_focal_loss / len(dataloader)\n",
    "    avg_dice_per_class = [np.mean(scores) for scores in dice_scores_per_class]\n",
    "    \n",
    "    return avg_loss, avg_dice_loss, avg_focal_loss, avg_dice_per_class\n",
    "\n",
    "print(\"‚úì Training and validation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Main Training Loop\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TRAINING (OPTIMIZED FOR 7,235 PATCHES)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Epochs: {config.EPOCHS}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Steps per epoch: {len(train_loader)}\")\n",
    "print(f\"Class weights (EXTREME): {config.CLASS_WEIGHTS}\")\n",
    "print(f\"\\nüí° Estimated time: ~8-10 hours total\")\n",
    "print(f\"   (~30-40 minutes per epoch)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_dice_loss': [],\n",
    "    'train_focal_loss': [],\n",
    "    'train_dice_per_class': [[] for _ in range(config.NUM_CLASSES)],\n",
    "    'val_loss': [],\n",
    "    'val_dice_loss': [],\n",
    "    'val_focal_loss': [],\n",
    "    'val_dice_per_class': [[] for _ in range(config.NUM_CLASSES)],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_val_loss = float('inf')\n",
    "best_val_dice = 0.0\n",
    "best_tumor_dice = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "# Training start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, config.EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_dice_loss, train_focal_loss, train_dice_per_class = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, scheduler, device, scaler, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice_loss, val_focal_loss, val_dice_per_class = validate(\n",
    "        model, val_loader, criterion, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Get current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Store metrics\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_dice_loss'].append(train_dice_loss)\n",
    "    history['train_focal_loss'].append(train_focal_loss)\n",
    "    for c in range(config.NUM_CLASSES):\n",
    "        history['train_dice_per_class'][c].append(train_dice_per_class[c])\n",
    "    \n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice_loss'].append(val_dice_loss)\n",
    "    history['val_focal_loss'].append(val_focal_loss)\n",
    "    for c in range(config.NUM_CLASSES):\n",
    "        history['val_dice_per_class'][c].append(val_dice_per_class[c])\n",
    "    \n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Calculate mean Dice scores\n",
    "    train_mean_dice = np.mean(train_dice_per_class)\n",
    "    val_mean_dice = np.mean(val_dice_per_class)\n",
    "    \n",
    "    # Calculate tumor-only Dice\n",
    "    train_tumor_dice = np.mean(train_dice_per_class[1:])\n",
    "    val_tumor_dice = np.mean(val_dice_per_class[1:])\n",
    "    \n",
    "    # Epoch summary\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EPOCH {epoch}/{config.EPOCHS} SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Time: {epoch_time:.2f}s | LR: {current_lr:.6f}\")\n",
    "    print(f\"\\nTrain - Loss: {train_loss:.4f} | Dice: {train_dice_loss:.4f} | Focal: {train_focal_loss:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f} | Dice: {val_dice_loss:.4f} | Focal: {val_focal_loss:.4f}\")\n",
    "    print(f\"\\nTrain - Mean Dice: {train_mean_dice:.4f} | Tumor Dice: {train_tumor_dice:.4f}\")\n",
    "    print(f\"Val   - Mean Dice: {val_mean_dice:.4f} | Tumor Dice: {val_tumor_dice:.4f}\")\n",
    "    print(f\"\\nPer-class Dice (Val):\")\n",
    "    class_names = ['Background', 'Necrotic', 'Edema', 'Enhancing']\n",
    "    for c, name in enumerate(class_names):\n",
    "        print(f\"  {name:12s}: {val_dice_per_class[c]:.4f}\")\n",
    "    \n",
    "    # Save best model based on tumor Dice\n",
    "    is_best = val_tumor_dice > best_tumor_dice\n",
    "    if is_best:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_dice = val_mean_dice\n",
    "        best_tumor_dice = val_tumor_dice\n",
    "        patience_counter = 0\n",
    "        \n",
    "        checkpoint_path = os.path.join(config.CHECKPOINT_DIR, 'best_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_mean_dice': val_mean_dice,\n",
    "            'val_tumor_dice': val_tumor_dice,\n",
    "            'val_dice_per_class': val_dice_per_class,\n",
    "            'config': config.__dict__\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        print(f\"\\n‚úì Best model saved! (Tumor Dice: {val_tumor_dice:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Save periodic checkpoint\n",
    "    if epoch % config.SAVE_EVERY_N_EPOCHS == 0:\n",
    "        checkpoint_path = os.path.join(config.CHECKPOINT_DIR, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        print(f\"‚úì Checkpoint saved at epoch {epoch}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.PATIENCE:\n",
    "        print(f\"\\n‚ö†Ô∏è  Early stopping triggered after {epoch} epochs\")\n",
    "        print(f\"No improvement for {config.PATIENCE} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Training complete\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"Best validation mean Dice: {best_val_dice:.4f}\")\n",
    "print(f\"Best validation tumor Dice: {best_tumor_dice:.4f}\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Save Training History\n",
    "\n",
    "# Convert history to DataFrame\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': range(1, len(history['train_loss']) + 1),\n",
    "    'train_loss': history['train_loss'],\n",
    "    'train_dice_loss': history['train_dice_loss'],\n",
    "    'train_focal_loss': history['train_focal_loss'],\n",
    "    'val_loss': history['val_loss'],\n",
    "    'val_dice_loss': history['val_dice_loss'],\n",
    "    'val_focal_loss': history['val_focal_loss'],\n",
    "    'learning_rate': history['learning_rates']\n",
    "})\n",
    "\n",
    "# Add per-class Dice scores\n",
    "class_names = ['Background', 'Necrotic', 'Edema', 'Enhancing']\n",
    "for c, name in enumerate(class_names):\n",
    "    history_df[f'train_dice_{name.lower()}'] = history['train_dice_per_class'][c]\n",
    "    history_df[f'val_dice_{name.lower()}'] = history['val_dice_per_class'][c]\n",
    "\n",
    "# Save to CSV\n",
    "history_path = os.path.join(config.RESULTS_DIR, 'training_history.csv')\n",
    "history_df.to_csv(history_path, index=False)\n",
    "\n",
    "print(\"‚úì Training history saved\")\n",
    "print(f\"  Location: {history_path}\")\n",
    "print(f\"\\nHistory DataFrame:\")\n",
    "print(history_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Plot Training Curves\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    \"\"\"Plot comprehensive training curves.\"\"\"\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Training Progress - Swin Transformer 3D (7,235 patches)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combined Loss\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('Combined Loss (Dice + Focal)', fontsize=13, fontweight='semibold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice Loss\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(epochs, history['train_dice_loss'], 'b-', label='Train Dice Loss', linewidth=2)\n",
    "    ax.plot(epochs, history['val_dice_loss'], 'r-', label='Val Dice Loss', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Dice Loss', fontsize=12)\n",
    "    ax.set_title('Dice Loss', fontsize=13, fontweight='semibold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Per-class Dice Score (Validation)\n",
    "    ax = axes[1, 0]\n",
    "    class_names = ['Background', 'Necrotic', 'Edema', 'Enhancing']\n",
    "    colors = ['blue', 'red', 'green', 'orange']\n",
    "    for c, (name, color) in enumerate(zip(class_names, colors)):\n",
    "        ax.plot(epochs, history['val_dice_per_class'][c], \n",
    "                color=color, label=name, linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Dice Score', fontsize=12)\n",
    "    ax.set_title('Validation Dice Score per Class', fontsize=13, fontweight='semibold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    # Learning Rate Schedule\n",
    "    ax = axes[1, 1]\n",
    "    ax.plot(epochs, history['learning_rates'], 'purple', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax.set_title('Learning Rate Schedule', fontsize=13, fontweight='semibold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(config.PLOTS_DIR, 'training_curves.png')\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Training curves saved: {plot_path}\")\n",
    "\n",
    "plot_training_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Visualize Predictions\n",
    "\n",
    "def visualize_predictions(model, dataloader, device, num_samples=3):\n",
    "    \"\"\"Visualize model predictions vs ground truth.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    class_names = ['Background', 'Necrotic', 'Edema', 'Enhancing']\n",
    "    colors = ['black', 'red', 'green', 'blue']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample_idx, (images, masks) in enumerate(dataloader):\n",
    "            if sample_idx >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Move to CPU\n",
    "            image = images[0].cpu().numpy()\n",
    "            mask = masks[0].cpu().numpy()\n",
    "            prediction = predictions[0].cpu().numpy()\n",
    "            \n",
    "            # Select middle slices\n",
    "            mid_d = image.shape[1] // 2\n",
    "            mid_h = image.shape[2] // 2\n",
    "            mid_w = image.shape[3] // 2\n",
    "            \n",
    "            # Create visualization\n",
    "            fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "            fig.suptitle(f'Sample {sample_idx + 1}: Predictions vs Ground Truth', \n",
    "                        fontsize=16, fontweight='bold')\n",
    "            \n",
    "            views = [\n",
    "                ('Axial', image[:, :, :, mid_w], mask[:, :, mid_w], prediction[:, :, mid_w]),\n",
    "                ('Coronal', image[:, :, mid_h, :], mask[:, mid_h, :], prediction[:, mid_h, :]),\n",
    "                ('Sagittal', image[:, mid_d, :, :], mask[mid_d, :, :], prediction[mid_d, :, :])\n",
    "            ]\n",
    "            \n",
    "            for row_idx, (view_name, img_slice, mask_slice, pred_slice) in enumerate(views):\n",
    "                # FLAIR\n",
    "                ax = axes[row_idx, 0]\n",
    "                ax.imshow(img_slice[0].T, cmap='gray', origin='lower')\n",
    "                ax.set_title(f'{view_name} - FLAIR', fontsize=11, fontweight='semibold')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # T1CE\n",
    "                ax = axes[row_idx, 1]\n",
    "                ax.imshow(img_slice[2].T, cmap='gray', origin='lower')\n",
    "                ax.set_title(f'{view_name} - T1CE', fontsize=11, fontweight='semibold')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Ground truth\n",
    "                ax = axes[row_idx, 2]\n",
    "                ax.imshow(mask_slice.T, cmap='jet', origin='lower', vmin=0, vmax=3)\n",
    "                ax.set_title(f'{view_name} - Ground Truth', fontsize=11, fontweight='semibold')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Prediction\n",
    "                ax = axes[row_idx, 3]\n",
    "                im = ax.imshow(pred_slice.T, cmap='jet', origin='lower', vmin=0, vmax=3)\n",
    "                ax.set_title(f'{view_name} - Prediction', fontsize=11, fontweight='semibold')\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # Colorbar\n",
    "            cbar = fig.colorbar(im, ax=axes, orientation='horizontal', \n",
    "                               fraction=0.046, pad=0.04)\n",
    "            cbar.set_ticks([0, 1, 2, 3])\n",
    "            cbar.set_ticklabels(class_names)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plot_path = os.path.join(config.PLOTS_DIR, f'prediction_sample_{sample_idx + 1}.png')\n",
    "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"‚úì Visualization saved: {plot_path}\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint_path = os.path.join(config.CHECKPOINT_DIR, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"\\n‚úì Loading checkpoint from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úì Model loaded successfully (Epoch {checkpoint['epoch']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING PREDICTION VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    visualize_predictions(model, val_loader, device, num_samples=3)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: No checkpoint found at {checkpoint_path}\")\n",
    "    print(\"Please run the training loop (Cell 10) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
